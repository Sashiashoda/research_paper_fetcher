{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31bf6770-2532-4d11-a89c-34bb359e76f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "Details fetched for PubMed ID: 40066684\n",
      "Details fetched for PubMed ID: 40066617\n",
      "Details fetched for PubMed ID: 40066584\n",
      "Details fetched for PubMed ID: 40066457\n",
      "Details fetched for PubMed ID: 40066440\n",
      "Details fetched for PubMed ID: 40066337\n",
      "Details fetched for PubMed ID: 40066323\n",
      "Details fetched for PubMed ID: 40066313\n",
      "Details fetched for PubMed ID: 40066304\n",
      "Details fetched for PubMed ID: 40066288\n",
      "Details fetched for PubMed ID: 40066219\n",
      "Details fetched for PubMed ID: 40066214\n",
      "Details fetched for PubMed ID: 40066211\n",
      "Details fetched for PubMed ID: 40066210\n",
      "Details fetched for PubMed ID: 40066194\n",
      "Details fetched for PubMed ID: 40066170\n",
      "Details fetched for PubMed ID: 40066124\n",
      "Details fetched for PubMed ID: 40066123\n",
      "Details fetched for PubMed ID: 40066115\n",
      "Details fetched for PubMed ID: 40066114\n",
      "Filtered data saved to papers.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "# Function to fetch papers from PubMed based on the search query\n",
    "def fetch_papers(query: str):\n",
    "    \"\"\"Fetch papers from PubMed based on a search query.\"\"\"\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query,  # Search term\n",
    "        'retmax': 20,  # Number of papers to fetch\n",
    "        'retmode': 'xml'  # We want the data in XML format\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Data fetched successfully!\")\n",
    "        return response.text  # Return the XML response text\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract PubMed IDs from the fetched data\n",
    "def extract_pubmed_ids(xml_data: str):\n",
    "    \"\"\"Extract PubMed IDs from the XML response.\"\"\"\n",
    "    tree = ElementTree.fromstring(xml_data)\n",
    "    ids = [id_elem.text for id_elem in tree.findall(\".//Id\")]\n",
    "    return ids\n",
    "\n",
    "# Function to fetch detailed information about a specific paper using its PubMed ID\n",
    "def fetch_paper_details(pubmed_id: str):\n",
    "    \"\"\"Fetch detailed information about a paper using its PubMed ID.\"\"\"\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': pubmed_id,  # PubMed ID of the paper\n",
    "        'retmode': 'xml'  # We want the data in XML format\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Details fetched for PubMed ID: {pubmed_id}\")\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Error fetching details for PubMed ID {pubmed_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to parse the detailed paper data and extract necessary information\n",
    "def parse_paper_data(xml_data: str):\n",
    "    \"\"\"Parse the XML data and extract relevant information.\"\"\"\n",
    "    tree = ElementTree.fromstring(xml_data)\n",
    "    \n",
    "    title = tree.find(\".//Item[@Name='Title']\").text if tree.find(\".//Item[@Name='Title']\") is not None else \"N/A\"\n",
    "    pub_date = tree.find(\".//PubDate\").text if tree.find(\".//PubDate\") is not None else \"N/A\"\n",
    "    \n",
    "    authors = []\n",
    "    affiliations = []\n",
    "    corresponding_email = \"N/A\"\n",
    "    \n",
    "    for author in tree.findall(\".//Author\"):\n",
    "        name = author.find(\"Name\").text if author.find(\"Name\") is not None else \"N/A\"\n",
    "        email = author.find(\"Affiliation\").text if author.find(\"Affiliation\") is not None else \"N/A\"\n",
    "        authors.append(name)\n",
    "        affiliations.append(email)\n",
    "        \n",
    "        if author.find(\"Email\") is not None:\n",
    "            corresponding_email = author.find(\"Email\").text\n",
    "    \n",
    "    return {\n",
    "        'Title': title,\n",
    "        'PubmedID': tree.find(\".//PubmedData//ArticleId\").text if tree.find(\".//PubmedData//ArticleId\") is not None else \"N/A\",\n",
    "        'Publication Date': pub_date,\n",
    "        'Authors': authors,\n",
    "        'Affiliations': affiliations,\n",
    "        'Corresponding Author Email': corresponding_email\n",
    "    }\n",
    "\n",
    "# Function to filter authors affiliated with pharmaceutical/biotech companies\n",
    "def filter_by_affiliation(data):\n",
    "    \"\"\"Filter out authors affiliated with pharmaceutical/biotech companies.\"\"\"\n",
    "    company_keywords = ['pharma', 'biotech', 'Pfizer', 'Moderna', 'Johnson & Johnson', 'AstraZeneca', 'Bayer', 'Novartis', 'Sanofi']\n",
    "    \n",
    "    filtered_data = []\n",
    "    for entry in data:\n",
    "        authors = entry['Authors']\n",
    "        affiliations = entry['Affiliations']\n",
    "        \n",
    "        non_academic_authors = []\n",
    "        companies = []\n",
    "        \n",
    "        for i, affiliation in enumerate(affiliations):\n",
    "            if any(keyword.lower() in affiliation.lower() for keyword in company_keywords):\n",
    "                non_academic_authors.append(authors[i])\n",
    "                companies.append(affiliation)\n",
    "        \n",
    "        if non_academic_authors:\n",
    "            filtered_data.append({\n",
    "                'PubMedID': entry['PubmedID'],\n",
    "                'Title': entry['Title'],\n",
    "                'Publication Date': entry['Publication Date'],\n",
    "                'Non-academic Author(s)': \", \".join(non_academic_authors),\n",
    "                'Company Affiliation(s)': \", \".join(companies),\n",
    "                'Corresponding Author Email': entry['Corresponding Author Email']\n",
    "            })\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Function to save filtered data to a CSV file\n",
    "def save_to_csv(data):\n",
    "    \"\"\"Save the filtered data to a CSV file.\"\"\"\n",
    "    with open('papers.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['PubMedID', 'Title', 'Publication Date', 'Non-academic Author(s)', 'Company Affiliation(s)', 'Corresponding Author Email']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "        print(\"Filtered data saved to papers.csv.\")\n",
    "\n",
    "# Main function to handle user input and execution\n",
    "def main():\n",
    "    \"\"\"Main function to handle user input and fetch papers.\"\"\"\n",
    "    # Manually set your search query here for testing\n",
    "    query = \"pharmaceutical research\"\n",
    "    \n",
    "    # Fetch papers based on the query\n",
    "    xml_data = fetch_papers(query)\n",
    "    \n",
    "    if xml_data:\n",
    "        # Extract PubMed IDs from the fetched data\n",
    "        pubmed_ids = extract_pubmed_ids(xml_data)\n",
    "        \n",
    "        # Initialize a list to store paper details\n",
    "        papers_data = []\n",
    "        \n",
    "        # Fetch detailed information for each paper using its PubMed ID\n",
    "        for pubmed_id in pubmed_ids:\n",
    "            paper_xml = fetch_paper_details(pubmed_id)\n",
    "            \n",
    "            if paper_xml:\n",
    "                paper_data = parse_paper_data(paper_xml)\n",
    "                papers_data.append(paper_data)\n",
    "        \n",
    "        # Filter papers by author affiliation with pharmaceutical/biotech companies\n",
    "        filtered_data = filter_by_affiliation(papers_data)\n",
    "        \n",
    "        # Save filtered data to a CSV file\n",
    "        save_to_csv(filtered_data)\n",
    "\n",
    "# Run the main function directly\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd93b353-97a0-4c03-870e-a1704b176a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\nanis\\ResearchPaperFetcher\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7572818e-7719-43dd-8a6e-27ba2b3c78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile README.md\n",
    "# Get Papers List\n",
    "\n",
    "This Python program fetches research papers from PubMed based on a user query. It filters the papers based on whether at least one author is affiliated with a pharmaceutical or biotech company, and returns the results in a CSV file.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Fetch research papers from PubMed API.\n",
    "- Filter results to identify authors affiliated with pharmaceutical or biotech companies.\n",
    "- Output the filtered results to a CSV file with the following columns:\n",
    "  - PubmedID: Unique identifier for the paper.\n",
    "  - Title: Title of the paper.\n",
    "  - Publication Date: Date the paper was published.\n",
    "  - Non-academic Author(s): Names of authors affiliated with non-academic institutions.\n",
    "  - Company Affiliation(s): Names of pharmaceutical/biotech companies.\n",
    "  - Corresponding Author Email: Email address of the corresponding author.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python 3.13 or higher\n",
    "- Poetry (for dependency management)\n",
    "- Dependencies will be automatically installed via `poetry install`.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Clone this repository to your local machine.\n",
    "   \n",
    "   ```bash\n",
    "   git clone https://github.com/your-username/get-papers-list.git\n",
    "   cd get-papers-list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4478b248-babb-4d6e-a0ae-7df066f3a928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for query: cancer research\n",
      "Searching for: cancer research\n",
      "API call successful.\n",
      "Response: <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>1824631</Count><RetMax>10</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>40066659</Id>\n",
      "<Id>40066656</Id>\n",
      "<Id>40066655</Id>\n",
      "<Id>40066650</Id>\n",
      "<Id>40066574</Id>\n",
      "<Id>40066501</Id>\n",
      "<Id>40066500</Id>\n",
      "<Id>40066468</Id>\n",
      "<Id>40066458</Id>\n",
      "<Id>40066453</Id>\n",
      "</IdList><TranslationSet><Translation>     <From>cancer research</From>     <To>\"Cancer Res\"[Journal:__jid2984705R] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</To>    </Translation></TranslationSet><QueryTranslation>\"cancer res\"[Journal] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</QueryTranslation></eSearchResult>\n",
      "\n",
      "Data to be saved:\n",
      "      Title             Authors       Source  Year\n",
      "0   Paper 1  Author A, Author B  Journal XYZ  2021\n",
      "1   Paper 2  Author A, Author B  Journal XYZ  2021\n",
      "2   Paper 3  Author A, Author B  Journal XYZ  2021\n",
      "3   Paper 4  Author A, Author B  Journal XYZ  2021\n",
      "4   Paper 5  Author A, Author B  Journal XYZ  2021\n",
      "5   Paper 6  Author A, Author B  Journal XYZ  2021\n",
      "6   Paper 7  Author A, Author B  Journal XYZ  2021\n",
      "7   Paper 8  Author A, Author B  Journal XYZ  2021\n",
      "8   Paper 9  Author A, Author B  Journal XYZ  2021\n",
      "9  Paper 10  Author A, Author B  Journal XYZ  2021\n",
      "Results saved to C:/Users/nanis/Desktop/papers.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def search_papers(query):\n",
    "    print(f\"Searching for: {query}\")\n",
    "    url = f\"https://api.ncbi.nlm.nih.gov/eutils/esearch.fcgi?db=pubmed&term={query}&retmax=10\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"API call successful.\")\n",
    "        print(\"Response:\", response.text)  # Print the raw response to check XML structure\n",
    "\n",
    "        # Parse the XML response\n",
    "        root = ET.fromstring(response.text)\n",
    "\n",
    "        # Extract the list of IDs\n",
    "        id_list = root.find('IdList').findall('Id')\n",
    "        paper_ids = [id_elem.text for id_elem in id_list]\n",
    "        \n",
    "        # Fetch details for each paper using the IDs (if needed)\n",
    "        return paper_ids\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def save_papers_to_csv(paper_ids, filename):\n",
    "    if not paper_ids:\n",
    "        print(\"No papers to save.\")\n",
    "        return\n",
    "\n",
    "    # Prepare mock data (or you can fetch detailed info using the paper_ids if necessary)\n",
    "    papers_details = [\n",
    "        {'Title': f'Paper {i+1}', 'Authors': 'Author A, Author B', 'Source': 'Journal XYZ', 'Year': '2021'}\n",
    "        for i in range(len(paper_ids))\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(papers_details)\n",
    "        print(f\"Data to be saved:\\n{df}\")  # Debug print to check if data is correct\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Results saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the CSV: {str(e)}\")\n",
    "\n",
    "def main(query, filename):\n",
    "    print(f\"Fetching papers for query: {query}\")\n",
    "    paper_ids = search_papers(query)\n",
    "    save_papers_to_csv(paper_ids, filename)\n",
    "\n",
    "# Running the function with a test query and output filename\n",
    "query = \"cancer research\"\n",
    "output_filename = \"C:/Users/nanis/Desktop/papers.csv\"  # Save to Desktop\n",
    "main(query=query, filename=output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba19ea0-040f-41eb-b0e8-7f61453393f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_papers(query):\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query,\n",
    "        'retmax': 10,  # Number of results to fetch\n",
    "        'retmode': 'xml'  # Change to 'json' if the response is expected in JSON format\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    print(\"API call successful.\")\n",
    "    print(\"Response:\", response.text)  # Print raw response to inspect it\n",
    "\n",
    "    try:\n",
    "        # If the response is in XML format, you might need to parse it as XML instead of JSON\n",
    "        if response.status_code == 200:\n",
    "            return response.text  # Returning raw XML if in XML format\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0a52b-7bdb-46ce-8d2d-cf1c89c510e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64cf5b26-2be9-484f-bd81-45e837211151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_papers_from_xml(xml_data):\n",
    "    try:\n",
    "        # Parse the XML data\n",
    "        root = ET.fromstring(xml_data)\n",
    "\n",
    "        # Extract paper IDs from the XML response\n",
    "        paper_ids = root.findall('.//Id')  # Find all the <Id> elements\n",
    "        paper_ids = [id_elem.text for id_elem in paper_ids]\n",
    "\n",
    "        print(f\"Found {len(paper_ids)} papers.\")\n",
    "        return paper_ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0119c31e-ac42-4d58-86c1-0cecf5493b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for query: cancer research\n",
      "API call successful.\n",
      "Response: <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>1824631</Count><RetMax>10</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>40066659</Id>\n",
      "<Id>40066656</Id>\n",
      "<Id>40066655</Id>\n",
      "<Id>40066650</Id>\n",
      "<Id>40066574</Id>\n",
      "<Id>40066501</Id>\n",
      "<Id>40066500</Id>\n",
      "<Id>40066468</Id>\n",
      "<Id>40066458</Id>\n",
      "<Id>40066453</Id>\n",
      "</IdList><TranslationSet><Translation>     <From>cancer research</From>     <To>\"Cancer Res\"[Journal:__jid2984705R] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</To>    </Translation></TranslationSet><QueryTranslation>\"cancer res\"[Journal] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</QueryTranslation></eSearchResult>\n",
      "\n",
      "Found 10 papers.\n",
      "Data to be saved:\n",
      "      Title             Authors       Source  Year\n",
      "0   Paper 1  Author A, Author B  Journal XYZ  2021\n",
      "1   Paper 2  Author A, Author B  Journal XYZ  2021\n",
      "2   Paper 3  Author A, Author B  Journal XYZ  2021\n",
      "3   Paper 4  Author A, Author B  Journal XYZ  2021\n",
      "4   Paper 5  Author A, Author B  Journal XYZ  2021\n",
      "5   Paper 6  Author A, Author B  Journal XYZ  2021\n",
      "6   Paper 7  Author A, Author B  Journal XYZ  2021\n",
      "7   Paper 8  Author A, Author B  Journal XYZ  2021\n",
      "8   Paper 9  Author A, Author B  Journal XYZ  2021\n",
      "9  Paper 10  Author A, Author B  Journal XYZ  2021\n",
      "Results saved to C:/Users/nanis/Desktop/papers.csv\n"
     ]
    }
   ],
   "source": [
    "def main(query, filename):\n",
    "    print(f\"Fetching papers for query: {query}\")\n",
    "    raw_data = search_papers(query)  # Get the raw response\n",
    "    \n",
    "    if raw_data:\n",
    "        # Parse XML if needed\n",
    "        paper_ids = parse_papers_from_xml(raw_data)\n",
    "        \n",
    "        if paper_ids:\n",
    "            save_papers_to_csv(paper_ids, filename)  # Save the data to CSV\n",
    "        else:\n",
    "            print(\"No papers found.\")\n",
    "    else:\n",
    "        print(\"Failed to fetch data.\")\n",
    "\n",
    "# Running the function with the query\n",
    "query = \"cancer research\"\n",
    "output_filename = \"C:/Users/nanis/Desktop/papers.csv\"  # Adjust path if needed\n",
    "main(query=query, filename=output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9b4ae11-fd7e-4a3c-9ebf-eed8c636bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for query: cancer research\n",
      "API call successful.\n",
      "Response: <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>1824631</Count><RetMax>10</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>40066659</Id>\n",
      "<Id>40066656</Id>\n",
      "<Id>40066655</Id>\n",
      "<Id>40066650</Id>\n",
      "<Id>40066574</Id>\n",
      "<Id>40066501</Id>\n",
      "<Id>40066500</Id>\n",
      "<Id>40066468</Id>\n",
      "<Id>40066458</Id>\n",
      "<Id>40066453</Id>\n",
      "</IdList><TranslationSet><Translation>     <From>cancer research</From>     <To>\"Cancer Res\"[Journal:__jid2984705R] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</To>    </Translation></TranslationSet><QueryTranslation>\"cancer res\"[Journal] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</QueryTranslation></eSearchResult>\n",
      "\n",
      "Found 10 papers.\n",
      "Data to be saved:\n",
      "      Title             Authors       Source  Year\n",
      "0   Paper 1  Author A, Author B  Journal XYZ  2021\n",
      "1   Paper 2  Author A, Author B  Journal XYZ  2021\n",
      "2   Paper 3  Author A, Author B  Journal XYZ  2021\n",
      "3   Paper 4  Author A, Author B  Journal XYZ  2021\n",
      "4   Paper 5  Author A, Author B  Journal XYZ  2021\n",
      "5   Paper 6  Author A, Author B  Journal XYZ  2021\n",
      "6   Paper 7  Author A, Author B  Journal XYZ  2021\n",
      "7   Paper 8  Author A, Author B  Journal XYZ  2021\n",
      "8   Paper 9  Author A, Author B  Journal XYZ  2021\n",
      "9  Paper 10  Author A, Author B  Journal XYZ  2021\n",
      "Results saved to C:/Users/nanis/Desktop/papers.csv\n"
     ]
    }
   ],
   "source": [
    "def main(query, filename):\n",
    "    print(f\"Fetching papers for query: {query}\")\n",
    "    raw_data = search_papers(query)  # Get the raw response\n",
    "    \n",
    "    if raw_data:\n",
    "        # Parse XML if needed\n",
    "        paper_ids = parse_papers_from_xml(raw_data)\n",
    "        \n",
    "        if paper_ids:\n",
    "            save_papers_to_csv(paper_ids, filename)  # Save the data to CSV\n",
    "        else:\n",
    "            print(\"No papers found.\")\n",
    "    else:\n",
    "        print(\"Failed to fetch data.\")\n",
    "\n",
    "# Running the function with the query\n",
    "query = \"cancer research\"\n",
    "output_filename = \"C:/Users/nanis/Desktop/papers.csv\"  # Adjust path if needed\n",
    "main(query=query, filename=output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "534f71f0-72fd-482f-bfc5-6268e1ffa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def fetch_paper_details(paper_id):\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': paper_id,\n",
    "        'retmode': 'xml',  # Get the data in XML format\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Parse the XML response\n",
    "        root = ET.fromstring(response.text)\n",
    "        \n",
    "        # Extract paper details\n",
    "        try:\n",
    "            title = root.find('.//ArticleTitle').text if root.find('.//ArticleTitle') else 'N/A'\n",
    "            authors = \", \".join([author.text for author in root.findall('.//Author/LastName')]) if root.findall('.//Author') else 'N/A'\n",
    "            source = root.find('.//Source').text if root.find('.//Source') else 'N/A'\n",
    "            year = root.find('.//PubDate/Year').text if root.find('.//PubDate/Year') else 'N/A'\n",
    "            \n",
    "            return {\n",
    "                \"Title\": title,\n",
    "                \"Authors\": authors,\n",
    "                \"Source\": source,\n",
    "                \"Year\": year\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting paper details: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch details for paper ID: {paper_id}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d3c550-2e67-4dcb-81c6-8e44a031e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for query: cancer research\n",
      "API call successful.\n",
      "Response: <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>1824631</Count><RetMax>10</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>40066659</Id>\n",
      "<Id>40066656</Id>\n",
      "<Id>40066655</Id>\n",
      "<Id>40066650</Id>\n",
      "<Id>40066574</Id>\n",
      "<Id>40066501</Id>\n",
      "<Id>40066500</Id>\n",
      "<Id>40066468</Id>\n",
      "<Id>40066458</Id>\n",
      "<Id>40066453</Id>\n",
      "</IdList><TranslationSet><Translation>     <From>cancer research</From>     <To>\"Cancer Res\"[Journal:__jid2984705R] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</To>    </Translation></TranslationSet><QueryTranslation>\"cancer res\"[Journal] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</QueryTranslation></eSearchResult>\n",
      "\n",
      "Found 10 papers.\n",
      "Fetching details for paper ID: 40066659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nanis\\AppData\\Local\\Temp\\ipykernel_12644\\17901509.py:20: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  title = root.find('.//ArticleTitle').text if root.find('.//ArticleTitle') else 'N/A'\n",
      "C:\\Users\\nanis\\AppData\\Local\\Temp\\ipykernel_12644\\17901509.py:23: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  year = root.find('.//PubDate/Year').text if root.find('.//PubDate/Year') else 'N/A'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching details for paper ID: 40066656\n",
      "Fetching details for paper ID: 40066655\n",
      "Fetching details for paper ID: 40066650\n",
      "Fetching details for paper ID: 40066574\n",
      "Fetching details for paper ID: 40066501\n",
      "Fetching details for paper ID: 40066500\n",
      "Fetching details for paper ID: 40066468\n",
      "Fetching details for paper ID: 40066458\n",
      "Fetching details for paper ID: 40066453\n",
      "Results saved to C:/Users/nanis/Desktop/papers.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_papers_to_csv(paper_ids, filename):\n",
    "    papers_details = []\n",
    "\n",
    "    # Fetch details for each paper and store them\n",
    "    for paper_id in paper_ids:\n",
    "        print(f\"Fetching details for paper ID: {paper_id}\")\n",
    "        details = fetch_paper_details(paper_id)\n",
    "        \n",
    "        if details:\n",
    "            papers_details.append(details)\n",
    "    \n",
    "    # Convert the list of paper details into a DataFrame and save to CSV\n",
    "    if papers_details:\n",
    "        df = pd.DataFrame(papers_details)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Results saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No paper details found to save.\")\n",
    "\n",
    "# Running the final main function\n",
    "def main(query, filename):\n",
    "    print(f\"Fetching papers for query: {query}\")\n",
    "    raw_data = search_papers(query)  # Get the raw response\n",
    "    \n",
    "    if raw_data:\n",
    "        # Parse XML if needed\n",
    "        paper_ids = parse_papers_from_xml(raw_data)\n",
    "        \n",
    "        if paper_ids:\n",
    "            save_papers_to_csv(paper_ids, filename)  # Save the data to CSV\n",
    "        else:\n",
    "            print(\"No papers found.\")\n",
    "    else:\n",
    "        print(\"Failed to fetch data.\")\n",
    "\n",
    "# Running the function with the query\n",
    "query = \"cancer research\"\n",
    "output_filename = \"C:/Users/nanis/Desktop/papers.csv\"  # Adjust path if needed\n",
    "main(query=query, filename=output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3b2824-097e-4be1-9a6c-1de7389cc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_papers_to_csv(papers, filename):\n",
    "    # If papers contain any data, proceed to save\n",
    "    if papers:\n",
    "        df = pd.DataFrame(papers)\n",
    "        try:\n",
    "            df.to_csv(filename, index=False)  # Save data to CSV\n",
    "            print(f\"Results saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving the CSV: {e}\")\n",
    "    else:\n",
    "        print(\"No papers found to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c37bf45-5627-40d8-8573-a6ebb13d3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [\n",
    "    {\"Title\": \"Paper 1\", \"Authors\": \"Author A, Author B\", \"Source\": \"Journal XYZ\", \"Year\": 2021},\n",
    "    {\"Title\": \"Paper 2\", \"Authors\": \"Author A, Author B\", \"Source\": \"Journal XYZ\", \"Year\": 2021}\n",
    "    # Add more papers...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46f4310f-83d8-42f7-b5ec-bb0d77f886e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for query: cancer research\n",
      "API call successful.\n",
      "Response: <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>1824631</Count><RetMax>10</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>40066659</Id>\n",
      "<Id>40066656</Id>\n",
      "<Id>40066655</Id>\n",
      "<Id>40066650</Id>\n",
      "<Id>40066574</Id>\n",
      "<Id>40066501</Id>\n",
      "<Id>40066500</Id>\n",
      "<Id>40066468</Id>\n",
      "<Id>40066458</Id>\n",
      "<Id>40066453</Id>\n",
      "</IdList><TranslationSet><Translation>     <From>cancer research</From>     <To>\"Cancer Res\"[Journal:__jid2984705R] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</To>    </Translation></TranslationSet><QueryTranslation>\"cancer res\"[Journal] OR (\"cancer\"[All Fields] AND \"research\"[All Fields]) OR \"cancer research\"[All Fields]</QueryTranslation></eSearchResult>\n",
      "\n",
      "Found 10 papers.\n",
      "Results saved to C:/Users/nanis/Desktop/papers.csv\n"
     ]
    }
   ],
   "source": [
    "query = \"cancer research\"\n",
    "output_filename = \"C:/Users/nanis/Desktop/papers.csv\"\n",
    "main(query=query, filename=output_filename)  # Run your main function to fetch and save the papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f94733-9a52-422e-a308-aa08c7860a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/nanis/Desktop\\papers.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "data = {\n",
    "    'Title': ['Paper 1', 'Paper 2', 'Paper 3'],\n",
    "    'Authors': ['Author A, Author B', 'Author A, Author B', 'Author A, Author B'],\n",
    "    'Source': ['Journal XYZ', 'Journal XYZ', 'Journal XYZ'],\n",
    "    'Year': [2021, 2021, 2021]\n",
    "}\n",
    "\n",
    "# Create DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the folder and filename\n",
    "output_directory = \"C:/Users/nanis/Desktop\"\n",
    "output_filename = \"papers.csv\"\n",
    "output_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Now save the file\n",
    "try:\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73256d1d-e162-45f8-97c6-a4d4577fd5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e20c9d-16f9-4aca-af25-c9dcbd8b1d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bec7f3-b594-46e2-af72-a8a422707c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
